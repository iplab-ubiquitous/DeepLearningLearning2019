{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYf8Z8Iwg_5Q",
        "colab_type": "text"
      },
      "source": [
        "## **データ読み込み軍団**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzVcWCl-ou6c",
        "colab_type": "code",
        "outputId": "f2aa8281-c1c3-4d4f-977d-3226c215cb58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#GPU処理になっているかの確認\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-2fw-n0Mm7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#googledriveAPIとpythonを連携する PyDriveをcolab上にインストール\n",
        "# ! をつかうとコマンドが使える\n",
        "\n",
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-I56ZRyMrv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ログインしているアカウントとgoogleドライブを連携する\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV6DlZGkHDTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ローカルからアップロードするとき用いる\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQKkH5f3NDhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#犬猫写真データをドライブからもってくる\n",
        "\n",
        "id = '1YacZJ9yYDmwew_FivQIrHBNowC9nSfDR'  # 共有リンクで取得した id= より後の部分\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('dogs-vs-cats-redux-kernels-edition.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yWJEQ71LZcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#学習済み重みをドライブからもってくる\n",
        "\n",
        "id = '1O05JOK_gxOu2iipU8S4RQv0oeINrnn4B'  # 共有リンクで取得した id= より後の部分\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('weights.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY8aPrY7kY_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip dogs-vs-cats-redux-kernels-edition.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAv5yW3Ckn8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip test.zip\n",
        "!unzip train.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFNzvnSWktcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip weights.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJQWRF77CKUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#全ての犬猫写真データから1000枚と400枚抜き出す\n",
        "#この1000枚を訓練データとする\n",
        "#400枚を検証データとする\n",
        "\n",
        "import os\n",
        "source_dir = \"./train\"\n",
        "train_dir = \"./data/train\"\n",
        "valid_dir = \"./data/validation\"\n",
        "result_dir = \"./results\"\n",
        "\n",
        "if not os.path.exists(\"%s/dogs\" % train_dir):\n",
        "  os.makedirs(\"%s/dogs\" % train_dir)\n",
        "  \n",
        "if not os.path.exists(\"%s/cats\" % train_dir):\n",
        "  os.makedirs(\"%s/cats\" % train_dir)\n",
        "  \n",
        "if not os.path.exists(\"%s/dogs\" % valid_dir):\n",
        "  os.makedirs(\"%s/dogs\" % valid_dir)\n",
        "  \n",
        "if not os.path.exists(\"%s/cats\" % valid_dir):\n",
        "  os.makedirs(\"%s/cats\" % valid_dir)\n",
        "  \n",
        "if not os.path.exists(result_dir):\n",
        "  os.makedirs(\"./results\")\n",
        "\n",
        "\n",
        "# 最初の1000枚の画像をtrain_dirに移動，移動なので元あった場所のファイルはなくなる\n",
        "for i in range(1000):\n",
        "    os.rename(\"%s/dog.%d.jpg\" % (source_dir, i + 1), \"%s/dogs/dog%04d.jpg\" % (train_dir, i + 1))\n",
        "    os.rename(\"%s/cat.%d.jpg\" % (source_dir, i + 1), \"%s/cats/cat%04d.jpg\" % (train_dir, i + 1))\n",
        "\n",
        "# 次の400枚の画像をvalid_dirに移動\n",
        "for i in range(400):\n",
        "    os.rename(\"%s/dog.%d.jpg\" % (source_dir, 1000 + i + 1), \"%s/dogs/dog%04d.jpg\" % (valid_dir, i + 1))\n",
        "    os.rename(\"%s/cat.%d.jpg\" % (source_dir, 1000 + i + 1), \"%s/cats/cat%04d.jpg\" % (valid_dir, i + 1))\n",
        "    \n",
        "print(\"end cell\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKmVGaifk5nS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#データ入ってるか確認用\n",
        "!ls data/train/dogs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Altf0LbcFFR1",
        "colab_type": "text"
      },
      "source": [
        "# Mnist 分類器の作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GHnUkZrogo-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#必要なライブラリのインポート\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input, Dropout\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "from keras import optimizers\n",
        "import numpy as np\n",
        "import os\n",
        "print(\"end cell\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSXfz3cWr4WC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ハイパパラメータたち\n",
        "INPUT_SHAPE = (1, 28, 28)\n",
        "CLASSES_NUM = 10\n",
        "EPOCH_NUM = 10\n",
        "BATCH_SIZE = 128\n",
        "K.set_image_dim_ordering('th')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G2Yaj5Yr8C2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#モデル\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=20, kernel_size=5, padding='same',input_shape=INPUT_SHAPE))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "model.add( Conv2D(filters=50, kernel_size=5, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(units=CLASSES_NUM))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gEE7CtYsFFt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6b3df2cb-1985-45a1-f7ee-12e7c69f82b7"
      },
      "source": [
        "#mnistのロードと画素の正規化\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npgbysRMsKz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cnnに入れられるよう軸を増やす\n",
        "\n",
        "x_train = x_train[:, np.newaxis, :, :]\n",
        "x_test = x_test[:, np.newaxis, :, :]\n",
        "\n",
        "#ラベルをone-hot vector化\n",
        "y_train = np_utils.to_categorical(\n",
        "    y=y_train, num_classes=CLASSES_NUM)\n",
        "y_test = np_utils.to_categorical(\n",
        "    y=y_test, num_classes=CLASSES_NUM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgWgkY9ksNa0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "7d9aa7b6-052c-49fb-f2ad-b37ab8e5901d"
      },
      "source": [
        "#モデルのコンパイルと学習\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#verbose...データをどこまでログに出すか\n",
        "#validation_split 検証データの割合\n",
        "history = model.fit(\n",
        "    x=x_train, y=y_train, batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCH_NUM, verbose=2, validation_split=0.2)\n",
        "\n",
        "Test = x_train[0]\n",
        "Test = Test[:, np.newaxis, :, :]\n",
        "\n",
        "test = model.predict(Test)\n",
        "\n",
        "print(\"Input: {}\".format(np.argmax(y_train[0])))\n",
        "print(\"Predict: {}\".format(np.argmax(test)))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.0026 - acc: 0.9994 - val_loss: 0.0873 - val_acc: 0.9883\n",
            "Epoch 2/10\n",
            " - 3s - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0689 - val_acc: 0.9900\n",
            "Epoch 3/10\n",
            " - 3s - loss: 2.8535e-04 - acc: 0.9999 - val_loss: 0.0666 - val_acc: 0.9915\n",
            "Epoch 4/10\n",
            " - 2s - loss: 3.7854e-04 - acc: 0.9999 - val_loss: 0.0697 - val_acc: 0.9913\n",
            "Epoch 5/10\n",
            " - 2s - loss: 0.0024 - acc: 0.9994 - val_loss: 0.0732 - val_acc: 0.9893\n",
            "Epoch 6/10\n",
            " - 3s - loss: 0.0025 - acc: 0.9994 - val_loss: 0.0760 - val_acc: 0.9897\n",
            "Epoch 7/10\n",
            " - 3s - loss: 0.0030 - acc: 0.9994 - val_loss: 0.0655 - val_acc: 0.9906\n",
            "Epoch 8/10\n",
            " - 3s - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0642 - val_acc: 0.9917\n",
            "Epoch 9/10\n",
            " - 3s - loss: 5.1657e-04 - acc: 0.9999 - val_loss: 0.0554 - val_acc: 0.9929\n",
            "Epoch 10/10\n",
            " - 3s - loss: 2.0301e-05 - acc: 1.0000 - val_loss: 0.0578 - val_acc: 0.9932\n",
            "Input: 5\n",
            "Predict: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu8vZLto7xbo",
        "colab_type": "text"
      },
      "source": [
        "#犬猫分類器の作成\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRUXiFYgTKZT",
        "colab_type": "text"
      },
      "source": [
        "## **前置き**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shL8h0tWo3lk",
        "colab_type": "code",
        "outputId": "a1c8dcf2-e8c6-4e26-cc30-9c1935996de9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#必要なライブラリのインポート\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input, Dropout\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import os\n",
        "print(\"end cell\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "end cell\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu-cZ0YoE3va",
        "colab_type": "code",
        "outputId": "0a3fffb9-719e-4858-9e34-b70f5b605937",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#学習時のlossや検証データでの正答率を記録する関数\n",
        "\n",
        "def save_history(history, result_file):\n",
        "    print(history.history.keys())\n",
        "    loss = history.history['loss']\n",
        "    acc = history.history['acc']\n",
        "    val_loss = history.history['val_loss']\n",
        "    val_acc = history.history['val_acc']\n",
        "    nb_epoch = len(acc)\n",
        "\n",
        "    with open(result_file, \"w\") as fp:\n",
        "        fp.write(\"epoch\\tloss\\tacc\\tval_loss\\tval_acc\\n\")\n",
        "        for i in range(nb_epoch):\n",
        "            fp.write(\"%d\\t%f\\t%f\\t%f\\t%f\\n\" % (i, loss[i], acc[i], val_loss[i], val_acc[i]))\n",
        "print(\"end cell\")\n",
        "          "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "end cell\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBJIZX7TNRJL",
        "colab_type": "code",
        "outputId": "2871bdbd-3820-4d93-fc4b-f9063535fd43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#画像の大きさ，訓練データのパス，epoch数などを設定\n",
        "\n",
        "img_width, img_height = 150, 150\n",
        "train_data_dir = './data/train'\n",
        "validtion_data_dir = './data/validation'\n",
        "nb_train_samples = 2000\n",
        "nb_validation_samples = 800\n",
        "nb_epochs = 20\n",
        "result_dir = './results'\n",
        "\n",
        "print(\"end cell\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "end cell\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUbIrzrcXGbb",
        "colab_type": "text"
      },
      "source": [
        "## 自作モデル\n",
        "\n",
        "畳み込み2層"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5yjLdPAW_gw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#モデルの作成\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, 3, 3, input_shape=(150, 150, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, 3, 3))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 訓練データとバリデーションデータを生成するジェネレータを作成\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'data/train',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    'data/validation',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "\n",
        "# 訓練\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    samples_per_epoch=2000,\n",
        "    nb_epoch=nb_epochs,\n",
        "    validation_data=validation_generator,\n",
        "    nb_val_samples=800)\n",
        "\n",
        "# 結果を保存\n",
        "model.save_weights(os.path.join(result_dir, 'smallcnn.h5'))\n",
        "save_history(history, os.path.join(result_dir, 'history_smallcnn.txt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASUH55-tpNa0",
        "colab_type": "text"
      },
      "source": [
        "**predict**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mTf03Zhar9N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "d26e9d3a-fb4f-4998-9e45-6073fe2d5fc0"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Activation, Dropout, Flatten, Dense\n",
        "from keras.preprocessing import image\n",
        "from IPython.display import Image, display_jpeg\n",
        "import numpy as np\n",
        "\n",
        "#ローカル用\n",
        "# if len(sys.argv) != 2:\n",
        "#   print(\"usage: python predict.py [filename]\")\n",
        "#   sys.exit(1)\n",
        "  \n",
        "# filename = sys.argv[1]\n",
        "filename = \"sample_cat2.jpg\"\n",
        "print(\"input:\",filename)\n",
        "\n",
        "result_dir = \"./results\"\n",
        "img_height, img_width = 150, 150\n",
        "channels = 3\n",
        "\n",
        "#モデルの作成\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, 3, 3, input_shape=(150, 150, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, 3, 3))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "\n",
        "#学習済みモデルをロード，コンパイル\n",
        "model.load_weights(os.path.join(result_dir, 'smallcnn.h5'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 画像をパスを参照して読み込み，ついでにサイズを調整する\n",
        "# cnnに入れるため，軸を一つ増やし，4次元テンソルへ変換 (h,w,rgb) -> (batchsize, h, w, rgb) 今回は軸増やすだけなのでbatchsize = 1となる\n",
        "img = image.load_img(filename, target_size = (img_height, img_width))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "#今回のモデルではcnnに入れる際，rgbを正規化する必要がある\n",
        "x = x/255.0\n",
        "\n",
        "\n",
        "#画像表示\n",
        "display_jpeg(Image(filename))\n",
        "\n",
        "#推測，2値分類なので，0.5をボーダーとし，高いか低いかで判定\n",
        "pred = model.predict(x)[0]\n",
        "\n",
        "if pred < 0.5:\n",
        "  print(\"cat\")\n",
        "else:\n",
        "  print(\"dog\")\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input: sample_cat2.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(150, 150,...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEAAkGBxISEhATERMQEA8QDw8PDw8QEhAPDw8PFRUWFhUR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\nFy5B/9k=\n"
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "dog\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Zi4BvYOm_eU",
        "colab_type": "text"
      },
      "source": [
        "## VGG16のfinetuning\n",
        "1epoch 132秒 2分12秒\n",
        "\n",
        "50epoch 1時間40分？？\n",
        "\n",
        "やってられないので20epoch 40分ちょい にした\n",
        "\n",
        "validationがめっちゃ時間かかる\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOgeXctHFUjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "#VGG16モデルをロード，ここは学習せず特徴抽出器として使う\n",
        "#学習を凍結させる処理は後ろで\n",
        "input_tensor = Input(shape=(img_height, img_width, 3))\n",
        "vgg16_model = VGG16(include_top = False, weights='imagenet', input_tensor = input_tensor)\n",
        "\n",
        "#全結合層構築\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten(input_shape = vgg16_model.output_shape[1:]))\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "#下のようにすれば多クラス分類にも対応できる\n",
        "# top_model.add(Dense(units=クラス数))\n",
        "# top_model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "\n",
        "#Funcrional APIを使って vggと全結合層をつなげる\n",
        "model = Model(input = vgg16_model.input, output=top_model(vgg16_model.output))\n",
        "print('vgg16_model:', vgg16_model)\n",
        "print('top_model:', top_model)\n",
        "print('model:', model)\n",
        "model.summary()\n",
        "\n",
        "for i in range(len(model.layers)):\n",
        "  print(i, model.layers[i])\n",
        "  \n",
        "for layer in model.layers[:15]:\n",
        "  layer.trainable = False\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer = optimizers.SGD(lr=1e-4, momentum = 0.9), metrics=['accuracy'])\n",
        "\n",
        "#rescale...各画素の情報を0-255から0-1に変換\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255, shear_range = 0.2, zoom_range =0.2, horizontal_flip = True)\n",
        "test_datagen = ImageDataGenerator(rescale =1.0 / 255)\n",
        "\n",
        "#訓練データにaugmentationをかけたデータを出力する生成器\n",
        "#ImageDataGenerator.flow_directoryが勝手に指定したディレクトリ下のディレクトリを探査，発見したディレクトリ下のファイルに自動でラベルつける\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size = 32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validtion_data_dir,\n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size = 32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "#ファインチューニング\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    samples_per_epoch=nb_train_samples,\n",
        "    nb_epoch = nb_epochs,\n",
        "    validation_data = validation_generator,\n",
        "    nb_val_samples=nb_validation_samples\n",
        "\n",
        ")\n",
        "\n",
        "model.save_weights(os.path.join(result_dir, 'finetuning.h5'))\n",
        "save_history(history, os.path.join(result_dir, 'history_finetuning.txt'))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG9JmuWtLF84",
        "colab_type": "text"
      },
      "source": [
        "### predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFwmngsGLEWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Activation, Dropout, Flatten, Dense\n",
        "from keras.preprocessing import image\n",
        "from IPython.display import Image, display_jpeg\n",
        "import numpy as np\n",
        "\n",
        "#ローカル用\n",
        "# if len(sys.argv) != 2:\n",
        "#   print(\"usage: python predict.py [filename]\")\n",
        "#   sys.exit(1)\n",
        "  \n",
        "# filename = sys.argv[1]\n",
        "filename = \"BUN.jpg\"\n",
        "print(\"input:\",filename)\n",
        "\n",
        "result_dir = \"./results\"\n",
        "img_height, img_width = 150, 150\n",
        "channels = 3\n",
        "\n",
        "#vgg16のロード\n",
        "input_tensor = Input(shape=(img_height, img_width, channels))\n",
        "vgg16_model = VGG16(include_top = False, weights = 'imagenet', input_tensor=input_tensor)\n",
        "\n",
        "#全結合層作成\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten(input_shape=vgg16_model.output_shape[1:]))\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "#vgg16と全結合層を結合\n",
        "model = Model(input=vgg16_model.input, output=top_model(vgg16_model.output))\n",
        "\n",
        "#学習済みモデルをロード，コンパイル，学習しないのでoptimizerは適当でも大丈夫\n",
        "model.load_weights(os.path.join(result_dir, 'finetuning_catdogs.h5'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 画像をコマンドライン引数でとったパスを参照して読み込み，ついでにサイズを調整する\n",
        "# cnnに入れるため，軸を一つ増やし，4次元テンソルへ変換 (h,w,rgb) -> (batchsize, h, w, rgb) 今回は軸増やすだけなのでbatchsize = 1となる\n",
        "img = image.load_img(filename, target_size = (img_height, img_width))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "#今回のモデルではcnnに入れる際，正規化する必要がある\n",
        "x = x/255.0\n",
        "\n",
        "\n",
        "#画像表示\n",
        "display_jpeg(Image(filename))\n",
        "\n",
        "#推測\n",
        "pred = model.predict(x)[0]\n",
        "print(pred)\n",
        "\n",
        "if pred < 0.5:\n",
        "  print(\"cat\")\n",
        "else:\n",
        "  print(\"dog\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}