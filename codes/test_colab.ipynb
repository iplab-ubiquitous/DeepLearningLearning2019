{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYf8Z8Iwg_5Q",
        "colab_type": "text"
      },
      "source": [
        "## **データ読み込み軍団**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzVcWCl-ou6c",
        "colab_type": "code",
        "outputId": "92bb541f-4313-4ed5-d7bf-8df36b36da5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#GPU処理になっているかの確認\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-2fw-n0Mm7l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "481b4992-5e65-48ed-b9e7-08fe69136539"
      },
      "source": [
        "#googledriveAPIとpythonを連携する PyDriveをcolab上にインストール\n",
        "# ! をつかうとコマンドが使える\n",
        "\n",
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 993kB 165kB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-I56ZRyMrv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ログインしているアカウントとgoogleドライブを連携する\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV6DlZGkHDTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ローカルからアップロードするとき用いる\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQKkH5f3NDhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#訓練用犬猫写真データをドライブからもってくる\n",
        "\n",
        "id = '1YacZJ9yYDmwew_FivQIrHBNowC9nSfDR'  # 共有リンクで取得した id= より後の部分\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('dogs-vs-cats-redux-kernels-edition.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK3aeCX3Lb-y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "d14eb6b8-816a-4a14-8e74-c243b023cd45"
      },
      "source": [
        "#テスト用サンプル犬猫写真データをドライブからもってくる\n",
        "\n",
        "id = '1numU6XX9wxaQth4al_dKyrBJ1PcSiJqc'  # 共有リンクで取得した id= より後の部分\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('sample_picture.zip')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0623 21:12:43.729654 140355203516288 __init__.py:44] file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 36, in autodetect\n",
            "    from google.appengine.api import memcache\n",
            "ModuleNotFoundError: No module named 'google.appengine'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 41, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    'file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth')\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yWJEQ71LZcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#学習済み重みをドライブからもってくる\n",
        "\n",
        "id = '1O05JOK_gxOu2iipU8S4RQv0oeINrnn4B'  # 共有リンクで取得した id= より後の部分\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('weights.zip')\n",
        "\n",
        "https://drive.google.com/open?id="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY8aPrY7kY_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip dogs-vs-cats-redux-kernels-edition.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAv5yW3Ckn8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip test.zip\n",
        "!unzip train.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFNzvnSWktcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip weights.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD8xUg4NLq3d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "5a35f23a-a58d-485c-da47-c414b2aeefad"
      },
      "source": [
        "!unzip sample_picture.zip"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  sample_picture.zip\n",
            "  inflating: sample_picture/sample_cat3.jpg  \n",
            "  inflating: sample_picture/agatsuma.jpg  \n",
            "  inflating: sample_picture/irst_dog2.jpg  \n",
            "  inflating: sample_picture/_DS_Store  \n",
            "  inflating: sample_picture/sample_cat2.jpg  \n",
            "  inflating: sample_picture/irst_cat3.jpeg  \n",
            "  inflating: sample_picture/Saga.jpg  \n",
            "  inflating: sample_picture/sample_cat4.jpg  \n",
            "  inflating: sample_picture/dog_cat.jpg  \n",
            "  inflating: sample_picture/sample_dog3.jpg  \n",
            "  inflating: sample_picture/irst_dog3.jpg  \n",
            "  inflating: sample_picture/irst_dog1.jpg  \n",
            "  inflating: sample_picture/BUN.jpg  \n",
            "  inflating: sample_picture/irst_cat1.jpg  \n",
            "  inflating: sample_picture/irst_cat2.jpg  \n",
            "  inflating: sample_picture/sample_cat5.jpg  \n",
            "  inflating: sample_picture/sample_dog2.jpg  \n",
            "  inflating: sample_picture/sample_cat.jpg  \n",
            "  inflating: sample_picture/sample_dog.jpg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJQWRF77CKUi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "edb292a1-507a-4c07-c8a4-ccf2ccdc766f"
      },
      "source": [
        "#全ての犬猫写真データから1000枚と400枚抜き出す\n",
        "#この1000枚を訓練データとする\n",
        "#400枚を検証データとする\n",
        "\n",
        "import os\n",
        "source_dir = \"./train\"\n",
        "train_dir = \"./data/train\"\n",
        "valid_dir = \"./data/validation\"\n",
        "result_dir = \"./results\"\n",
        "\n",
        "if not os.path.exists(\"%s/dogs\" % train_dir):\n",
        "  os.makedirs(\"%s/dogs\" % train_dir)\n",
        "  \n",
        "if not os.path.exists(\"%s/cats\" % train_dir):\n",
        "  os.makedirs(\"%s/cats\" % train_dir)\n",
        "  \n",
        "if not os.path.exists(\"%s/dogs\" % valid_dir):\n",
        "  os.makedirs(\"%s/dogs\" % valid_dir)\n",
        "  \n",
        "if not os.path.exists(\"%s/cats\" % valid_dir):\n",
        "  os.makedirs(\"%s/cats\" % valid_dir)\n",
        "  \n",
        "if not os.path.exists(result_dir):\n",
        "  os.makedirs(\"./results\")\n",
        "\n",
        "\n",
        "# 最初の1000枚の画像をtrain_dirに移動，移動なので元あった場所のファイルはなくなる\n",
        "for i in range(1000):\n",
        "    os.rename(\"%s/dog.%d.jpg\" % (source_dir, i + 1), \"%s/dogs/dog%04d.jpg\" % (train_dir, i + 1))\n",
        "    os.rename(\"%s/cat.%d.jpg\" % (source_dir, i + 1), \"%s/cats/cat%04d.jpg\" % (train_dir, i + 1))\n",
        "\n",
        "# 次の400枚の画像をvalid_dirに移動\n",
        "for i in range(400):\n",
        "    os.rename(\"%s/dog.%d.jpg\" % (source_dir, 1000 + i + 1), \"%s/dogs/dog%04d.jpg\" % (valid_dir, i + 1))\n",
        "    os.rename(\"%s/cat.%d.jpg\" % (source_dir, 1000 + i + 1), \"%s/cats/cat%04d.jpg\" % (valid_dir, i + 1))\n",
        "    \n",
        "print(\"end cell\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "end cell\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKmVGaifk5nS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#データ入ってるか確認用\n",
        "!ls data/train/dogs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Altf0LbcFFR1",
        "colab_type": "text"
      },
      "source": [
        "# Mnist 分類器の作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GHnUkZrogo-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "56636822-f2cd-4a50-a568-a5dbf5d7935b"
      },
      "source": [
        "#必要なライブラリのインポート\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input, Dropout\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "from keras import optimizers\n",
        "import numpy as np\n",
        "import os\n",
        "print(\"end cell\")"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "end cell\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSXfz3cWr4WC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ハイパパラメータたち\n",
        "INPUT_SHAPE = (1, 28, 28)\n",
        "CLASSES_NUM = 10\n",
        "EPOCH_NUM = 10\n",
        "BATCH_SIZE = 128\n",
        "K.set_image_dim_ordering('th')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G2Yaj5Yr8C2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#モデル\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=20, kernel_size=5, padding='same',input_shape=INPUT_SHAPE))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "model.add( Conv2D(filters=50, kernel_size=5, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(units=CLASSES_NUM))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gEE7CtYsFFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#mnistのロードと画素の正規化\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npgbysRMsKz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cnnに入れられるよう軸を増やす\n",
        "\n",
        "x_train = x_train[:, np.newaxis, :, :]\n",
        "x_test = x_test[:, np.newaxis, :, :]\n",
        "\n",
        "#ラベルをone-hot vector化\n",
        "y_train = np_utils.to_categorical(\n",
        "    y=y_train, num_classes=CLASSES_NUM)\n",
        "y_test = np_utils.to_categorical(\n",
        "    y=y_test, num_classes=CLASSES_NUM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgWgkY9ksNa0",
        "colab_type": "code",
        "outputId": "97917259-7281-4d57-bad9-4b3874e12c0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "#モデルのコンパイルと学習\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#verbose...データをどこまでログに出すか\n",
        "#validation_split 検証データの割合\n",
        "history = model.fit(\n",
        "    x=x_train, y=y_train, batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCH_NUM, verbose=2, validation_split=0.2)\n",
        "\n",
        "Test = x_train[0]\n",
        "Test = Test[:, np.newaxis, :, :]\n",
        "\n",
        "test = model.predict(Test)\n",
        "\n",
        "print(\"Input: {}\".format(np.argmax(y_train[0])))\n",
        "print(\"Predict: {}\".format(np.argmax(test)))"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 0.1858 - acc: 0.9445 - val_loss: 0.0579 - val_acc: 0.9828\n",
            "Epoch 2/10\n",
            " - 3s - loss: 0.0490 - acc: 0.9842 - val_loss: 0.0424 - val_acc: 0.9869\n",
            "Epoch 3/10\n",
            " - 3s - loss: 0.0323 - acc: 0.9895 - val_loss: 0.0374 - val_acc: 0.9889\n",
            "Epoch 4/10\n",
            " - 3s - loss: 0.0228 - acc: 0.9926 - val_loss: 0.0334 - val_acc: 0.9899\n",
            "Epoch 5/10\n",
            " - 3s - loss: 0.0175 - acc: 0.9945 - val_loss: 0.0344 - val_acc: 0.9897\n",
            "Epoch 6/10\n",
            " - 3s - loss: 0.0133 - acc: 0.9956 - val_loss: 0.0337 - val_acc: 0.9912\n",
            "Epoch 7/10\n",
            " - 3s - loss: 0.0098 - acc: 0.9968 - val_loss: 0.0416 - val_acc: 0.9897\n",
            "Epoch 8/10\n",
            " - 3s - loss: 0.0084 - acc: 0.9970 - val_loss: 0.0410 - val_acc: 0.9899\n",
            "Epoch 9/10\n",
            " - 3s - loss: 0.0078 - acc: 0.9975 - val_loss: 0.0397 - val_acc: 0.9902\n",
            "Epoch 10/10\n",
            " - 3s - loss: 0.0090 - acc: 0.9968 - val_loss: 0.0527 - val_acc: 0.9893\n",
            "Input: 5\n",
            "Predict: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu8vZLto7xbo",
        "colab_type": "text"
      },
      "source": [
        "#犬猫分類器の作成\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRUXiFYgTKZT",
        "colab_type": "text"
      },
      "source": [
        "## **前置き**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shL8h0tWo3lk",
        "colab_type": "code",
        "outputId": "d39a57ed-3e16-4c5e-f020-5f8545589cd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#必要なライブラリのインポート\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input, Dropout\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import os\n",
        "print(\"end cell\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "end cell\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu-cZ0YoE3va",
        "colab_type": "code",
        "outputId": "4c8a72d0-4d78-4ba5-89ed-c565911febfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#学習時のlossや検証データでの正答率を記録する関数\n",
        "\n",
        "def save_history(history, result_file):\n",
        "    print(history.history.keys())\n",
        "    loss = history.history['loss']\n",
        "    acc = history.history['acc']\n",
        "    val_loss = history.history['val_loss']\n",
        "    val_acc = history.history['val_acc']\n",
        "    nb_epoch = len(acc)\n",
        "\n",
        "    with open(result_file, \"w\") as fp:\n",
        "        fp.write(\"epoch\\tloss\\tacc\\tval_loss\\tval_acc\\n\")\n",
        "        for i in range(nb_epoch):\n",
        "            fp.write(\"%d\\t%f\\t%f\\t%f\\t%f\\n\" % (i, loss[i], acc[i], val_loss[i], val_acc[i]))\n",
        "print(\"end cell\")\n",
        "          "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "end cell\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBJIZX7TNRJL",
        "colab_type": "code",
        "outputId": "857fde00-720c-45b2-d7cd-babaf6343507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#画像の大きさ，訓練データのパス，epoch数などを設定\n",
        "\n",
        "img_width, img_height = 150, 150\n",
        "train_data_dir = './data/train'\n",
        "validtion_data_dir = './data/validation'\n",
        "nb_train_samples = 2000\n",
        "nb_validation_samples = 800\n",
        "nb_epochs = 20\n",
        "result_dir = './results'\n",
        "K.set_image_dim_ordering('tf')\n",
        "\n",
        "print(\"end cell\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "end cell\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUbIrzrcXGbb",
        "colab_type": "text"
      },
      "source": [
        "## 自作モデル\n",
        "\n",
        "畳み込み2層"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5yjLdPAW_gw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "outputId": "3447ac9e-b7a2-4384-c74b-8b9358e94cdf"
      },
      "source": [
        "#モデルの作成\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, 3, 3, input_shape=(150, 150, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, 3, 3))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 訓練データとバリデーションデータを生成するジェネレータを作成\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'data/train',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    'data/validation',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "\n",
        "# 訓練\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    samples_per_epoch=2000,\n",
        "    nb_epoch=nb_epochs,\n",
        "    validation_data=validation_generator,\n",
        "    nb_val_samples=800)\n",
        "\n",
        "# 結果を保存\n",
        "model.save_weights(os.path.join(result_dir, 'smallcnn.h5'))\n",
        "save_history(history, os.path.join(result_dir, 'history_smallcnn.txt'))"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(150, 150,...)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 800 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., steps_per_epoch=62, epochs=20, validation_steps=800)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-1f9ad444157b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     nb_val_samples=800)\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# 結果を保存\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdo_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    507\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[1;32m    508\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m                         loss=self.total_loss)\n\u001b[0m\u001b[1;32m    510\u001b[0m                 updates = (self.updates +\n\u001b[1;32m    511\u001b[0m                            \u001b[0mtraining_updates\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mvhats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mvhats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvhats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/optimizers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mvhats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mvhats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvhats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mzeros\u001b[0;34m(shape, dtype, name)\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpy_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mvariable\u001b[0;34m(value, dtype, name, constraint)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_learning_phase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m   def _variable_v2_call(cls,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m                         shape=None):\n\u001b[1;32m    197\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2509\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2510\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2511\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m   2512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1566\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1568\u001b[0;31m           shape=shape)\n\u001b[0m\u001b[1;32m   1569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, expected_shape, constraint, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1742\u001b[0m             _try_guard_against_uninitialized_dependencies(\n\u001b[1;32m   1743\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1744\u001b[0;31m                 self._initial_value),\n\u001b[0m\u001b[1;32m   1745\u001b[0m             validate_shape=validate_shape).op\n\u001b[1;32m   1746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_try_guard_against_uninitialized_dependencies\u001b[0;34m(name, initial_value)\u001b[0m\n\u001b[1;32m   2511\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_has_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2513\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_safe_initial_value_from_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_safe_initial_value_from_tensor\u001b[0;34m(name, tensor, op_cache)\u001b[0m\n\u001b[1;32m   2546\u001b[0m   \u001b[0mnew_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2547\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mnew_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2548\u001b[0;31m     \u001b[0mnew_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_initial_value_from_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2549\u001b[0m     \u001b[0mop_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnew_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_safe_initial_value_from_op\u001b[0;34m(name, op, op_cache)\u001b[0m\n\u001b[1;32m   2565\u001b[0m     \u001b[0mmodifications\u001b[0m \u001b[0mneed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mmade\u001b[0m \u001b[0mthen\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mop\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mreturned\u001b[0m \u001b[0munchanged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2566\u001b[0m   \"\"\"\n\u001b[0;32m-> 2567\u001b[0;31m   \u001b[0mop_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2568\u001b[0m   if op_type in (\"IsVariableInitialized\", \"VarIsInitializedOp\",\n\u001b[1;32m   2569\u001b[0m                  \"ReadVariableOp\"):\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnode_def\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2532\u001b[0m     \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2533\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2534\u001b[0;31m       \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationToNodeDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2535\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2536\u001b[0m     \u001b[0mnode_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_def_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNodeDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASUH55-tpNa0",
        "colab_type": "text"
      },
      "source": [
        "**predict**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mTf03Zhar9N",
        "colab_type": "code",
        "outputId": "4935bddc-e0e3-4bda-f8be-91c1a21218da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "import os\n",
        "import sys\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Activation, Dropout, Flatten, Dense\n",
        "from keras.preprocessing import image\n",
        "from IPython.display import Image, display_jpeg\n",
        "import numpy as np\n",
        "\n",
        "#ローカル用\n",
        "# if len(sys.argv) != 2:\n",
        "#   print(\"usage: python predict.py [filename]\")\n",
        "#   sys.exit(1)\n",
        "  \n",
        "# filename = sys.argv[1]\n",
        "\n",
        "print(\"smallCNN\")\n",
        "filename = \"sample_cat2.jpg\"\n",
        "print(\"input:\",filename)\n",
        "\n",
        "result_dir = \"./weights\"\n",
        "img_height, img_width = 150, 150\n",
        "channels = 3\n",
        "\n",
        "#モデルの作成\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, 3, 3, input_shape=(150, 150, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, 3, 3))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "\n",
        "#学習済みモデルをロード，コンパイル\n",
        "model.load_weights(os.path.join(result_dir, 'smallcnn.h5'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 画像をパスを参照して読み込み，ついでにサイズを調整する\n",
        "# cnnに入れるため，軸を一つ増やし，4次元テンソルへ変換\n",
        "#(h,w,rgb) -> (batchsize, h, w, rgb) 今回は軸増やすだけなのでbatchsize = 1となる\n",
        "img = image.load_img(filename, target_size = (img_height, img_width))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "#今回のモデルではcnnに入れる際，rgbを正規化する必要がある\n",
        "x = x/255.0\n",
        "\n",
        "\n",
        "#画像表示\n",
        "display_jpeg(Image(filename))\n",
        "\n",
        "#推測，2値分類なので，0.5をボーダーとし，高いか低いかで判定\n",
        "pred = model.predict(x)[0]\n",
        "print(pred)\n",
        "\n",
        "if pred < 0.5:\n",
        "  print(\"cat\")\n",
        "else:\n",
        "  print(\"dog\")\n"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "smallCNN\n",
            "input: sample_cat2.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(150, 150,...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEAAkGBxISEhATERMQEA8QDw8PDw8QEhAPDw8PFRUWFhUR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\nFy5B/9k=\n"
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0.92423284]\n",
            "dog\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Zi4BvYOm_eU",
        "colab_type": "text"
      },
      "source": [
        "## VGG16のfinetuning\n",
        "1epoch 132秒 2分12秒\n",
        "\n",
        "50epoch 1時間40分？？\n",
        "\n",
        "やってられないので20epoch 40分ちょい にした\n",
        "\n",
        "validationがめっちゃ時間かかる\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOgeXctHFUjg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "c9e309a9-af35-49f8-abf4-dd2c7eba6a19"
      },
      "source": [
        "\n",
        "\n",
        "#VGG16モデルをロード，ここは学習せず特徴抽出器として使う\n",
        "#学習を凍結させる処理は後ろで\n",
        "input_tensor = Input(shape=(img_height, img_width, 3))\n",
        "vgg16_model = VGG16(include_top = False, weights='imagenet', input_tensor = input_tensor)\n",
        "\n",
        "#全結合層構築\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten(input_shape = vgg16_model.output_shape[1:]))\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "#下のようにすれば多クラス分類にも対応できる\n",
        "# top_model.add(Dense(units=クラス数))\n",
        "# top_model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "\n",
        "#Funcrional APIを使って vggと全結合層をつなげる\n",
        "model = Model(input = vgg16_model.input, output=top_model(vgg16_model.output))\n",
        "print('vgg16_model:', vgg16_model)\n",
        "print('top_model:', top_model)\n",
        "print('model:', model)\n",
        "model.summary()\n",
        "\n",
        "for i in range(len(model.layers)):\n",
        "  print(i, model.layers[i])\n",
        "  \n",
        "for layer in model.layers[:15]:\n",
        "  layer.trainable = False\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer = optimizers.SGD(lr=1e-4, momentum = 0.9), metrics=['accuracy'])\n",
        "\n",
        "#rescale...各画素の情報を0-255から0-1に変換\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255, shear_range = 0.2, zoom_range =0.2, horizontal_flip = True)\n",
        "test_datagen = ImageDataGenerator(rescale =1.0 / 255)\n",
        "\n",
        "#訓練データにaugmentationをかけたデータを出力する生成器\n",
        "#ImageDataGenerator.flow_directoryが勝手に指定したディレクトリ下のディレクトリを探査，発見したディレクトリ下のファイルに自動でラベルつける\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size = 32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validtion_data_dir,\n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size = 32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "#ファインチューニング\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    samples_per_epoch=nb_train_samples,\n",
        "    nb_epoch = nb_epochs,\n",
        "    validation_data = validation_generator,\n",
        "    nb_val_samples=nb_validation_samples\n",
        "\n",
        ")\n",
        "\n",
        "model.save_weights(os.path.join(result_dir, 'finetuning.h5'))\n",
        "save_history(history, os.path.join(result_dir, 'history_finetuning.txt'))\n",
        "\n"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1863\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1864\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1865\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for 'block2_pool_14/MaxPool' (op: 'MaxPool') with input shapes: [?,128,75,1].",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-4c3c319c0160>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvgg16_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#全結合層構築\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtop_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/applications/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utils'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/applications/vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mvgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_applications/vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m                       \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                       name='block2_conv2')(x)\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'block2_pool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;31m# Block 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/pooling.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    203\u001b[0m                                         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                                         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                                         data_format=self.data_format)\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/pooling.py\u001b[0m in \u001b[0;36m_pooling_function\u001b[0;34m(self, inputs, pool_size, strides, padding, data_format)\u001b[0m\n\u001b[1;32m    266\u001b[0m         output = K.pool2d(inputs, pool_size, strides,\n\u001b[1;32m    267\u001b[0m                           \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                           pool_mode='max')\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mpool2d\u001b[0;34m(x, pool_size, strides, padding, data_format, pool_mode)\u001b[0m\n\u001b[1;32m   3976\u001b[0m         x = tf.nn.max_pool(x, pool_size, strides,\n\u001b[1;32m   3977\u001b[0m                            \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3978\u001b[0;31m                            data_format=tf_data_format)\n\u001b[0m\u001b[1;32m   3979\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'avg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3980\u001b[0m         x = tf.nn.avg_pool(x, pool_size, strides,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[0;34m(value, ksize, strides, padding, data_format, name, input)\u001b[0m\n\u001b[1;32m   3754\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3755\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3756\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   3757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[0;34m(input, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   5670\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   5671\u001b[0m         \u001b[0;34m\"MaxPool\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5672\u001b[0;31m                    data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m   5673\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5674\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[1;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    789\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3614\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3615\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3616\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3617\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3618\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2025\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   2026\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 2027\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   2028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2029\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1865\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for 'block2_pool_14/MaxPool' (op: 'MaxPool') with input shapes: [?,128,75,1]."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG9JmuWtLF84",
        "colab_type": "text"
      },
      "source": [
        "### predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFwmngsGLEWG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "1b51ba25-2f0d-49f8-f903-bedd82ce3ae2"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Activation, Dropout, Flatten, Dense\n",
        "from keras.preprocessing import image\n",
        "from IPython.display import Image, display_jpeg\n",
        "import numpy as np\n",
        "\n",
        "#ローカル用 コマンドライン引数でpath読み込み\n",
        "# if len(sys.argv) != 2:\n",
        "#   print(\"usage: python predict.py [filename]\")\n",
        "#   sys.exit(1)\n",
        "  \n",
        "# filename = sys.argv[1]\n",
        "\n",
        "print(\"VGG16\")\n",
        "filename = \"agatsuma.jpg\"\n",
        "print(\"input:\",filename)\n",
        "\n",
        "result_dir = \"./weights\"\n",
        "img_height, img_width = 150, 150\n",
        "channels = 3\n",
        "\n",
        "#vgg16のロード\n",
        "input_tensor = Input(shape=(img_height, img_width, channels))\n",
        "vgg16_model = VGG16(include_top = False, weights = 'imagenet', input_tensor=input_tensor)\n",
        "\n",
        "#全結合層作成\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten(input_shape=vgg16_model.output_shape[1:]))\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "#vgg16と全結合層を結合\n",
        "model = Model(input=vgg16_model.input, output=top_model(vgg16_model.output))\n",
        "\n",
        "#学習済みモデルをロード，コンパイル，学習しないのでoptimizerは適当でも大丈夫\n",
        "model.load_weights(os.path.join(result_dir, 'finetuning_catdogs.h5'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 画像をコマンドライン引数でとったパスを参照して読み込み，ついでにサイズを調整する\n",
        "# cnnに入れるため，軸を一つ増やし，4次元テンソルへ変換 (h,w,rgb) -> (batchsize, h, w, rgb) 今回は軸増やすだけなのでbatchsize = 1となる\n",
        "img = image.load_img(filename, target_size = (img_height, img_width))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "#今回のモデルではcnnに入れる際，正規化する必要がある\n",
        "x = x/255.0\n",
        "\n",
        "\n",
        "#画像表示\n",
        "display_jpeg(Image(filename))\n",
        "\n",
        "#推測\n",
        "pred = model.predict(x)[0]\n",
        "print(pred)\n",
        "\n",
        "if pred < 0.5:\n",
        "  print(\"cat\")\n",
        "else:\n",
        "  print(\"dog\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG16\n",
            "input: agatsuma.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"se...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQAASABIAAD/4RiIRXhpZgAATU0AKgAAAAgACgEPAAIAAAAIAAAAhgEQAAIA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\nnk84zyay9tXfFP8Ax9n/AHT/ADSqdeutj5GT1Z//2Q==\n"
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0.97795594]\n",
            "dog\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}